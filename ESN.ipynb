{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import random\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir():\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        input_size = input dimension\n",
    "        hidden_size = number of internal (hidden) units in the reservoir\n",
    "        sparsity = percentage of elements in W_in equal to zero\n",
    "        spectral_radius = maximal absolute eigenvalue of matrix (W)*\n",
    "        a = input scaling (of W_in) (how \"nonlinear\" reservoir responses are)*\n",
    "        leak = leaking rate (speed of reservoir update dynamics over time)*\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size = 1000, sparsity = 0.9, \n",
    "        spectral_radius = 0.99, a = 0.6, leak = 1.0):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sparsity = sparsity\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.a = a\n",
    "        self.leak = leak\n",
    "        self.w_in = self.gen_w_in()\n",
    "        self.w = self.gen_w()\n",
    "        # self.w_in = torch.load('w_in.pt')\n",
    "        # self.w = torch.load('w.pt')\n",
    "        self.x = torch.zeros(self.hidden_size, 1)\n",
    "  \n",
    "    # [gen_w_in] generates random input weight matrix, [w_in], of size \n",
    "    # [hidden_size x input + 1], with values normally distributed around zero. \n",
    "    def gen_w_in(self):\n",
    "        w_in = torch.randn(self.hidden_size, self.input_size+1).normal_(mean=0.0, std=0.6)\n",
    "        torch.save(w_in, 'w_in_1k.pt') # save w_in\n",
    "        return w_in\n",
    "\n",
    "    # [gen_w] generates the internal weight matrix, [w], of size \n",
    "    # [hidden_size x hidden_size]. [w] is generated sparse with nonzero elements \n",
    "    # having a normal distribution centered around zero.\n",
    "    def gen_w(self):\n",
    "        w = torch.randn(self.hidden_size, self.hidden_size).normal_(mean=0.0, std=0.6)\n",
    "        for i in range(w.shape[0]): \n",
    "            for j in range(w[0].shape[0]):\n",
    "                if random() <= self.sparsity:\n",
    "                    w[i][j] = 0\n",
    "        eigenvalues = torch.eig(w)[0]\n",
    "        eig_max = torch.max(eigenvalues).item()\n",
    "        w *= self.spectral_radius / eig_max\n",
    "        torch.save(w, 'w_1k.pt') # save w\n",
    "        return w\n",
    "  \n",
    "    # [forward_reservoir] updates and returns the state representation [x] \n",
    "    # for given input [u]. \n",
    "    def forward_reservoir(self, u, current_x):\n",
    "        temp_state = torch.tanh(torch.mm(self.w_in, \n",
    "        torch.cat((torch.tensor([[1.0]]),u),0)) + torch.mm(self.w, current_x))\n",
    "        new_state = (1-self.leak) * current_x + self.leak * temp_state\n",
    "        self.x = new_state\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN(nn.Module): \n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size = 1000):\n",
    "        super().__init__()\n",
    "        self.reservoir = Reservoir(input_size, hidden_size)\n",
    "        # self.reservoir2 = Reservoir(hidden_size, hidden_size)\n",
    "        # self.reservoir3 = Reservoir(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(in_features=hidden_size, \n",
    "        out_features=output_size)  # linear layer\n",
    "        # normalize resultant vector into probability distribution\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.calls = 1 \n",
    "\n",
    "    # pass in 1 x 28 x 28 image\n",
    "    def forward(self, inp):\n",
    "        u = inp.flatten() # flatten image into single vector\n",
    "        u = u.unsqueeze(dim=0).t() # transpose to desired input shape for reservoir\n",
    "        x_r = self.reservoir.forward_reservoir(u, self.reservoir.x) # pass through reservoir\n",
    "        # if self.calls % len_data == (len_data-1):\n",
    "        #   torch.save(x_r, 'state_x_'+str(round(self.calls/len_data))+'.pt') # save state vector\n",
    "        # self.calls += 1\n",
    "        # x_r = self.reservoir2.forward_reservoir(x_r, self.reservoir.x) # pass through reservoir again\n",
    "        # x_r = self.reservoir3.forward_reservoir(x_r, self.reservoir.x) # pass through reservoir again\n",
    "        H = self.fc(x_r.t()) # pass transposed output x through linear layer\n",
    "        H_soft = self.softmax(H) # softmax\n",
    "        return H_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = ESN(784,10) # create instance (size 784 represents flattened 28x28 image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(esn.parameters(), lr=1e-5)\n",
    "len_data = len(trainset)\n",
    "nsamples = 500\n",
    "nepochs = 20\n",
    "esn = esn.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [train] trains the network\n",
    "def train():\n",
    "    start = time.time()\n",
    "    for epoch in range(nepochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainset, 0):\n",
    "            if i > nsamples: \n",
    "                break\n",
    "            images, labels = data\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = esn(images)\n",
    "            loss = criterion(outputs, torch.tensor([labels]))\n",
    "    \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % nsamples == (nsamples-1):  # print every 60000 mini-batches (1 epoch)\n",
    "                print('epoch %d, loss: %.3f' %\n",
    "                      (epoch, running_loss / nsamples))\n",
    "              \n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': esn.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': running_loss/len_data,\n",
    "                    }, '/Users/ryanhill/Desktop/Classical-RC/models/model_'+str(epoch))\n",
    "      \n",
    "    end = time.time()\n",
    "    print(\"total time = \" + str(end - start) + \" sec\")  # time in seconds\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [test] evaluates the networks accuracy\n",
    "def test():\n",
    "    start = time.time()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(testset, 0):\n",
    "        images, labels = data\n",
    "        pred = torch.argmax(esn(images)).item()\n",
    "        if pred == labels:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    correct = correct*100.0 / total\n",
    "    print(\"Accuracy: \" + str(correct) + \"%\")\n",
    "    end = time.time()\n",
    "    print(\"total time = \" + str(end - start) + \" sec\")  # time in seconds\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 2.298\n",
      "epoch 1, loss: 2.275\n",
      "epoch 2, loss: 2.248\n",
      "epoch 3, loss: 2.218\n",
      "epoch 4, loss: 2.188\n",
      "epoch 5, loss: 2.159\n",
      "epoch 6, loss: 2.131\n",
      "epoch 7, loss: 2.106\n",
      "epoch 8, loss: 2.083\n",
      "epoch 9, loss: 2.061\n",
      "epoch 10, loss: 2.041\n",
      "epoch 11, loss: 2.022\n",
      "epoch 12, loss: 2.006\n",
      "epoch 13, loss: 1.990\n",
      "epoch 14, loss: 1.976\n",
      "epoch 15, loss: 1.963\n",
      "epoch 16, loss: 1.949\n",
      "epoch 17, loss: 1.934\n",
      "epoch 18, loss: 1.919\n",
      "epoch 19, loss: 1.906\n",
      "total time = 14.358032941818237 sec\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.55%\n",
      "total time = 7.518266677856445 sec\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
